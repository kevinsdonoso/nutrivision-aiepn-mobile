// â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
// â•‘                         camera_frame_processor.dart                           â•‘
// â•‘              Procesador de frames de cÃ¡mara para detecciÃ³n YOLO               â•‘
// â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
// â•‘  Convierte frames de cÃ¡mara (YUV420) a formato RGB para inferencia.           â•‘
// â•‘  Usa cÃ³digo nativo C++ (si disponible) o Isolates como fallback.              â•‘
// â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import 'package:camera/camera.dart';
import 'package:flutter/foundation.dart';
import 'package:image/image.dart' as img;

import '../../../core/constants/app_constants.dart';
import '../../../core/exceptions/app_exceptions.dart';
import '../../../data/models/detection.dart';
import 'image_processing_isolate.dart';
import 'native_image_processor.dart';
import 'yolo_detector.dart';

/// Procesador de frames de cÃ¡mara para detecciÃ³n en tiempo real.
///
/// Maneja:
/// - ConversiÃ³n YUV420 â†’ RGB
/// - RotaciÃ³n segÃºn orientaciÃ³n del sensor
/// - Throttling para evitar sobrecarga
/// - InvocaciÃ³n del detector YOLO
class CameraFrameProcessor {
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // PROPIEDADES
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  final YoloDetector _detector;

  /// Indica si se estÃ¡ procesando un frame actualmente.
  bool _isProcessing = false;

  /// Contador de frames para throttling.
  int _frameCounter = 0;

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // CONSTRUCTOR
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  CameraFrameProcessor(this._detector);

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // GETTERS
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  /// Indica si el procesador estÃ¡ ocupado.
  bool get isBusy => _isProcessing;

  /// NÃºmero de frames procesados.
  int get processedFrames => _frameCounter;

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // PROCESAMIENTO PRINCIPAL
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  /// Intenta procesar un frame de cÃ¡mara.
  ///
  /// Retorna `null` si:
  /// - Ya se estÃ¡ procesando otro frame
  /// - No han pasado suficientes frames (throttling)
  /// - El tiempo mÃ­nimo entre inferencias no ha pasado
  ///
  /// [cameraImage] - Frame de la cÃ¡mara en formato YUV420
  /// [sensorOrientation] - OrientaciÃ³n del sensor de la cÃ¡mara en grados
  /// [isFrontCamera] - Si es la cÃ¡mara frontal (para espejo)
  Future<ProcessingResult?> processFrame(
    CameraImage cameraImage, {
    int sensorOrientation = 90,
    bool isFrontCamera = false,
  }) async {
    // SIMPLIFICADO: Solo verificar si estÃ¡ ocupado
    // El flag isBusy ya proporciona throttling natural
    // Los checks adicionales descartaban frames innecesariamente
    if (_isProcessing) {
      return null;
    }

    _frameCounter++;
    _isProcessing = true;

    try {
      final stopwatch = Stopwatch()..start();

      img.Image? finalImage;
      int outputWidth = cameraImage.width;
      int outputHeight = cameraImage.height;

      // Intentar conversiÃ³n nativa primero (mÃ¡s rÃ¡pida)
      if (NativeImageProcessor.isAvailable) {
        finalImage = await _tryNativeConversion(
          cameraImage,
          sensorOrientation,
          isFrontCamera,
        );
      }

      // Fallback a isolate si nativo no disponible/fallÃ³
      if (finalImage == null) {
        _debugLog('ğŸ“¦ Usando fallback ISOLATE (nativo no disponible/fallÃ³)');
        final isolateResult = await _convertWithIsolate(
          cameraImage,
          sensorOrientation,
          isFrontCamera,
        );
        if (isolateResult != null) {
          finalImage = isolateResult.image;
          outputWidth = isolateResult.width;
          outputHeight = isolateResult.height;
        }
      } else {
        _debugLog('âš¡ Usando conversiÃ³n NATIVA C++');
        // Ajustar dimensiones segÃºn rotaciÃ³n
        if (sensorOrientation == 90 || sensorOrientation == 270) {
          final temp = outputWidth;
          outputWidth = outputHeight;
          outputHeight = temp;
        }
      }

      if (finalImage == null) {
        _debugLog('âš ï¸ No se pudo convertir el frame');
        return null;
      }

      // Ejecutar detecciÃ³n (verbose: false para evitar logs en tiempo real)
      final detections = await _detector.detect(
        finalImage,
        confidenceThreshold: AppConstants.realtimeConfidenceThreshold,
        verbose: false,
      );

      stopwatch.stop();

      return ProcessingResult(
        detections: detections,
        inferenceTimeMs: stopwatch.elapsedMilliseconds,
        imageWidth: outputWidth,
        imageHeight: outputHeight,
      );
    } on NutriVisionException {
      rethrow;
    } catch (e, stackTrace) {
      throw FrameConversionException(
        message: 'Error procesando frame: $e',
        originalError: e,
        stackTrace: stackTrace,
      );
    } finally {
      _isProcessing = false;
    }
  }

  /// Intenta conversiÃ³n usando cÃ³digo nativo C++.
  Future<img.Image?> _tryNativeConversion(
    CameraImage cameraImage,
    int sensorOrientation,
    bool isFrontCamera,
  ) async {
    try {
      if (cameraImage.planes.length < 3) return null;

      final yPlane = cameraImage.planes[0];
      final uPlane = cameraImage.planes[1];
      final vPlane = cameraImage.planes[2];

      final rgbBytes = await NativeImageProcessor.convertYuvToRgb(
        yBytes: Uint8List.fromList(yPlane.bytes),
        uBytes: Uint8List.fromList(uPlane.bytes),
        vBytes: Uint8List.fromList(vPlane.bytes),
        width: cameraImage.width,
        height: cameraImage.height,
        yRowStride: yPlane.bytesPerRow,
        uvRowStride: uPlane.bytesPerRow,
        uvPixelStride: uPlane.bytesPerPixel ?? 1,
      );

      if (rgbBytes == null) return null;

      // Crear imagen desde bytes RGB
      final image = img.Image.fromBytes(
        width: cameraImage.width,
        height: cameraImage.height,
        bytes: rgbBytes.buffer,
        format: img.Format.uint8,
        numChannels: 3,
      );

      // Rotar segÃºn orientaciÃ³n
      img.Image rotatedImage;
      switch (sensorOrientation) {
        case 90:
          rotatedImage = img.copyRotate(image, angle: 90);
          break;
        case 180:
          rotatedImage = img.copyRotate(image, angle: 180);
          break;
        case 270:
          rotatedImage = img.copyRotate(image, angle: 270);
          break;
        default:
          rotatedImage = image;
      }

      // Espejo para cÃ¡mara frontal
      return isFrontCamera ? img.flipHorizontal(rotatedImage) : rotatedImage;
    } catch (e) {
      _debugLog('âš ï¸ Error en conversiÃ³n nativa: $e');
      return null;
    }
  }

  /// Convierte usando isolate (fallback).
  Future<_IsolateResult?> _convertWithIsolate(
    CameraImage cameraImage,
    int sensorOrientation,
    bool isFrontCamera,
  ) async {
    final input = _prepareIsolateInput(
      cameraImage,
      sensorOrientation,
      isFrontCamera,
    );

    if (input == null) return null;

    final conversionResult = await compute(
      convertYuvToRgbIsolate,
      input,
    );

    if (!conversionResult.isSuccess || conversionResult.rgbBytes == null) {
      _debugLog('âš ï¸ ConversiÃ³n en isolate fallÃ³: ${conversionResult.error}');
      return null;
    }

    // OPTIMIZACIÃ“N: Crear imagen desde bytes RGB crudos (sin PNG decode)
    final image = img.Image.fromBytes(
      width: conversionResult.width,
      height: conversionResult.height,
      bytes: conversionResult.rgbBytes!.buffer,
      format: img.Format.uint8,
      numChannels: 3,
    );

    return _IsolateResult(
      image: image,
      width: conversionResult.width,
      height: conversionResult.height,
    );
  }

  /// Prepara los datos del frame para enviar al isolate.
  YuvConversionInput? _prepareIsolateInput(
    CameraImage cameraImage,
    int sensorOrientation,
    bool isFrontCamera,
  ) {
    try {
      if (cameraImage.planes.length < 3) {
        _debugLog('âš ï¸ Frame no tiene 3 planos YUV');
        return null;
      }

      final yPlane = cameraImage.planes[0];
      final uPlane = cameraImage.planes[1];
      final vPlane = cameraImage.planes[2];

      return YuvConversionInput(
        width: cameraImage.width,
        height: cameraImage.height,
        yBytes: Uint8List.fromList(yPlane.bytes),
        uBytes: Uint8List.fromList(uPlane.bytes),
        vBytes: Uint8List.fromList(vPlane.bytes),
        yRowStride: yPlane.bytesPerRow,
        uvRowStride: uPlane.bytesPerRow,
        uvPixelStride: uPlane.bytesPerPixel ?? 1,
        sensorOrientation: sensorOrientation,
        flipHorizontal: isFrontCamera,
      );
    } catch (e) {
      _debugLog('âŒ Error preparando input para isolate: $e');
      return null;
    }
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // UTILIDADES
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  /// Resetea el contador de frames.
  void resetCounter() {
    _frameCounter = 0;
  }

  /// Log condicional solo en modo debug.
  void _debugLog(String message) {
    if (kDebugMode) {
      debugPrint('[CameraFrameProcessor] $message');
    }
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// RESULTADO DEL PROCESAMIENTO
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/// Resultado del procesamiento de un frame.
class ProcessingResult {
  /// Detecciones encontradas en el frame.
  final List<Detection> detections;

  /// Tiempo de inferencia en milisegundos.
  final int inferenceTimeMs;

  /// Ancho de la imagen procesada.
  final int imageWidth;

  /// Alto de la imagen procesada.
  final int imageHeight;

  const ProcessingResult({
    required this.detections,
    required this.inferenceTimeMs,
    required this.imageWidth,
    required this.imageHeight,
  });

  /// NÃºmero de detecciones.
  int get count => detections.length;

  /// FPS estimado basado en tiempo de inferencia.
  double get estimatedFps =>
      inferenceTimeMs > 0 ? 1000 / inferenceTimeMs : 0;

  @override
  String toString() =>
      'ProcessingResult(detections: $count, time: ${inferenceTimeMs}ms, fps: ${estimatedFps.toStringAsFixed(1)})';
}

/// Resultado interno de conversiÃ³n en isolate.
class _IsolateResult {
  final img.Image image;
  final int width;
  final int height;

  const _IsolateResult({
    required this.image,
    required this.width,
    required this.height,
  });
}
